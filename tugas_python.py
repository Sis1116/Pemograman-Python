# -*- coding: utf-8 -*-
"""Tugas Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZsB2cIvX-ttr5guXqYouukXJmlUEsIr4
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Colab Notebook 1

ls

# import the necessary packages
from keras.models import Sequential
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dense
from keras.optimizers import Adam
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import  train_test_split
from sklearn.metrics import classification_report
from PIL import Image
from imutils import paths
import numpy as np
import os

# grab all image paths in the input dataset directory, then initialize
# our list of images and corresponding class labels
print("[INFO] loading images....")
imagePaths = paths.list_images("3scene")
data = []
labels = []

# loop over our input images
for imagePath in imagePaths:
  # load the input image from disk, resize it to 64x64 pixels, scale
  # the pixel intensities to the range [0, 1], and then update our
  # images list
  image = Image.open(imagePath)
  image = np.array(image.resize((64, 64))) / 255.0
  data.append(image)
  
  # extract the class label from the file path and update the 
  # labels list
  label = imagePath.split(os.path.sep)[-2]
  labels.append(label)

print(labels)

# endcode the labels, converting them from strings to integers
lb = LabelBinarizer()
labels = lb.fit_transform(labels)

print(labels)

# perform a training and testing split using 75% of data for 
# training and 25% and evaluation
(trainX, testX, trainY, testY) = train_test_split(np.array(data), np.array(labels), test_size=0.25)
print(trainX.shape)
print(testX.shape)

from keras.models import Sequential
from keras.layers.core import Flatten
from keras.layers.core import Dense

model = Sequential(
    [
       Flatten(input_shape=(64*64*3,)),
       Dense(100, activation="relu", name="layer1"),
       Dense(16, activation="relu", name="layer2"),
       Dense(16, activation="relu", name="layer3"),
       Dense(3, activation= "softmax", name="layer4"),
    ]
)

model.summary()

# train the model using the Adam optimizer
print("[INFO] training network....")
opt = Adam(lr=1e-3, decay=1e-3 / 50)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=25, batch_size=32)

import matplotlib.pyplot as plt

print(H.history.keys())
# summarize history for accuracy
plt.plot(H.history['accuracy'])
plt.plot(H.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(H.history['loss'])
plt.plot(H.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# evaluate the network
print("[INFO] evaluating network...")
predictions = model.predict(testX, batch_size=32)
print(classification_report(testY.argmax(axis=1),
          predictions.argmax(axis=1), target_names=lb.classes_))

model.save('nnmodel_scene')

img_array = cv2.imread(image1)
plt.imshow(img_array)
  plt.show()
# print(type(img_array))

img_array = cv2.imread(image1)
plt.imshow(img_array)
plt.show()
# print(type(img_array))

image_testing = Image.open('forest_test.jpg')
image_testing = np.array(image_testing.resize((64, 64))) / 255.0
image_testing.shape

image_testing =  np.expand_dims(image_testing, axis=0)
print(image_testing.shape)

output = model.predict(image_testing, 1)
print(output)
print(lb.classes_[output.argmax(axis=1)])